"""Initial migration with all tables

Revision ID: 8b98e0e8972e
Revises: 
Create Date: 2025-07-07 01:18:39.861622

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '8b98e0e8972e'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('resource_exercises')
    op.drop_table('content_analysis_queue')
    op.drop_table('learning_content')
    op.drop_table('resource_questions')
    with op.batch_alter_table('skill_resources', schema=None) as batch_op:
        batch_op.drop_index('idx_skill_resources_resource')
        batch_op.drop_index('idx_skill_resources_skill')

    op.drop_table('skill_resources')
    with op.batch_alter_table('educational_resources', schema=None) as batch_op:
        batch_op.add_column(sa.Column('estimated_duration_minutes', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('ai_analysis_summary', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('transcript', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('last_analyzed', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('status', sa.String(length=50), nullable=True))
        batch_op.drop_index('idx_resources_category')
        batch_op.drop_index('idx_resources_cost')
        batch_op.drop_index('idx_resources_difficulty')
        batch_op.drop_index('idx_resources_quality')
        batch_op.drop_index('idx_resources_type')
        batch_op.drop_column('keywords')
        batch_op.drop_column('tags')
        batch_op.drop_column('sequence_order')
        batch_op.drop_column('discovery_method')
        batch_op.drop_column('skill_category')
        batch_op.drop_column('metadata')
        batch_op.drop_column('estimated_duration')
        batch_op.drop_column('cost_type')
        batch_op.drop_column('publication_date')
        batch_op.drop_column('author')
        batch_op.drop_column('learning_objectives')
        batch_op.drop_column('learning_level')
        batch_op.drop_column('learning_outcomes')
        batch_op.drop_column('ai_analysis_date')
        batch_op.drop_column('last_updated')
        batch_op.drop_column('prerequisites')
        batch_op.drop_column('content_extracted')
        batch_op.drop_column('ai_analysis_details')
        batch_op.drop_column('ai_analysis_score')

    with op.batch_alter_table('emerging_skills', schema=None) as batch_op:
        batch_op.add_column(sa.Column('market_demand_evidence', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('last_updated', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('status', sa.String(length=50), nullable=True))
        batch_op.add_column(sa.Column('source', sa.String(length=100), nullable=True))
        batch_op.drop_constraint('emerging_skills_skill_name_key', type_='unique')
        batch_op.drop_column('keywords')
        batch_op.drop_column('job_market_data')
        batch_op.drop_column('source_analysis')
        batch_op.drop_column('updated_date')
        batch_op.drop_column('related_skills')
        batch_op.drop_column('discovery_status')
        batch_op.drop_column('demand_trend')

    with op.batch_alter_table('learning_sessions', schema=None) as batch_op:
        batch_op.add_column(sa.Column('session_token', sa.String(length=255), nullable=False))
        batch_op.add_column(sa.Column('resource_id', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('started_date', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('completed_date', sa.DateTime(), nullable=True))
        batch_op.add_column(sa.Column('progress_percentage', sa.Float(), nullable=True))
        batch_op.alter_column('skill_id',
               existing_type=sa.INTEGER(),
               nullable=False)
        batch_op.drop_constraint('learning_sessions_session_id_key', type_='unique')
        batch_op.create_foreign_key(None, 'educational_resources', ['resource_id'], ['id'])
        batch_op.drop_column('session_id')
        batch_op.drop_column('session_data')
        batch_op.drop_column('created_date')
        batch_op.drop_column('user_preferences')

    with op.batch_alter_table('skill_learning_paths', schema=None) as batch_op:
        batch_op.add_column(sa.Column('resource_id', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('sequence_order', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('path_type', sa.String(length=50), nullable=True))
        batch_op.add_column(sa.Column('is_required', sa.Boolean(), nullable=True))
        batch_op.alter_column('skill_id',
               existing_type=sa.INTEGER(),
               nullable=False)
        batch_op.create_foreign_key(None, 'educational_resources', ['resource_id'], ['id'])
        batch_op.drop_column('path_name')
        batch_op.drop_column('path_description')
        batch_op.drop_column('difficulty_level')
        batch_op.drop_column('prerequisites')
        batch_op.drop_column('path_order')
        batch_op.drop_column('estimated_duration')
        batch_op.drop_column('learning_objectives')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('skill_learning_paths', schema=None) as batch_op:
        batch_op.add_column(sa.Column('learning_objectives', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('estimated_duration', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('path_order', sa.INTEGER(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('prerequisites', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('difficulty_level', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('path_description', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('path_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.alter_column('skill_id',
               existing_type=sa.INTEGER(),
               nullable=True)
        batch_op.drop_column('is_required')
        batch_op.drop_column('path_type')
        batch_op.drop_column('sequence_order')
        batch_op.drop_column('resource_id')

    with op.batch_alter_table('learning_sessions', schema=None) as batch_op:
        batch_op.add_column(sa.Column('user_preferences', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('created_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('session_data', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('session_id', sa.VARCHAR(length=100), autoincrement=False, nullable=False))
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_unique_constraint('learning_sessions_session_id_key', ['session_id'])
        batch_op.alter_column('skill_id',
               existing_type=sa.INTEGER(),
               nullable=True)
        batch_op.drop_column('progress_percentage')
        batch_op.drop_column('completed_date')
        batch_op.drop_column('started_date')
        batch_op.drop_column('resource_id')
        batch_op.drop_column('session_token')

    with op.batch_alter_table('emerging_skills', schema=None) as batch_op:
        batch_op.add_column(sa.Column('demand_trend', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('discovery_status', sa.VARCHAR(length=50), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('related_skills', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('updated_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('source_analysis', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('job_market_data', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('keywords', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.create_unique_constraint('emerging_skills_skill_name_key', ['skill_name'])
        batch_op.drop_column('source')
        batch_op.drop_column('status')
        batch_op.drop_column('last_updated')
        batch_op.drop_column('market_demand_evidence')

    with op.batch_alter_table('educational_resources', schema=None) as batch_op:
        batch_op.add_column(sa.Column('ai_analysis_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('ai_analysis_details', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('content_extracted', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('prerequisites', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('last_updated', sa.DATE(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('ai_analysis_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('learning_outcomes', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('learning_level', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('learning_objectives', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('author', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('publication_date', sa.DATE(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('cost_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('estimated_duration', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('metadata', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('skill_category', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('discovery_method', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('sequence_order', sa.INTEGER(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('tags', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('keywords', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.create_index('idx_resources_type', ['resource_type'], unique=False)
        batch_op.create_index('idx_resources_quality', ['quality_score'], unique=False)
        batch_op.create_index('idx_resources_difficulty', ['difficulty_level'], unique=False)
        batch_op.create_index('idx_resources_cost', ['cost_type'], unique=False)
        batch_op.create_index('idx_resources_category', ['skill_category'], unique=False)
        batch_op.drop_column('status')
        batch_op.drop_column('last_analyzed')
        batch_op.drop_column('transcript')
        batch_op.drop_column('ai_analysis_summary')
        batch_op.drop_column('estimated_duration_minutes')

    op.create_table('skill_resources',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('skill_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('resource_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('relevance_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('created_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['resource_id'], ['educational_resources.id'], name='skill_resources_resource_id_fkey'),
    sa.ForeignKeyConstraint(['skill_id'], ['emerging_skills.id'], name='skill_resources_skill_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='skill_resources_pkey')
    )
    with op.batch_alter_table('skill_resources', schema=None) as batch_op:
        batch_op.create_index('idx_skill_resources_skill', ['skill_id'], unique=False)
        batch_op.create_index('idx_skill_resources_resource', ['resource_id'], unique=False)

    op.create_table('resource_questions',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('resource_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('questions_data', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['resource_id'], ['educational_resources.id'], name='resource_questions_resource_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='resource_questions_pkey')
    )
    op.create_table('learning_content',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('resource_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('content_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('content_data', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('ai_generated_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('content_metadata', sa.TEXT(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['resource_id'], ['educational_resources.id'], name='learning_content_resource_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='learning_content_pkey')
    )
    op.create_table('content_analysis_queue',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('resource_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('priority', sa.INTEGER(), server_default=sa.text('1'), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=True),
    sa.Column('analysis_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('queued_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('started_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('completed_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['resource_id'], ['educational_resources.id'], name='content_analysis_queue_resource_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='content_analysis_queue_pkey')
    )
    op.create_table('resource_exercises',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('resource_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('exercises_data', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_date', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['resource_id'], ['educational_resources.id'], name='resource_exercises_resource_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='resource_exercises_pkey')
    )
    # ### end Alembic commands ###
